{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98b7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dbb34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- Salary Estimate: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Type of ownership: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- job_state: string (nullable = true)\n",
      " |-- company_age: integer (nullable = true)\n",
      " |-- python: integer (nullable = true)\n",
      " |-- spark: integer (nullable = true)\n",
      " |-- tableau: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"q3\").getOrCreate()\n",
    "filepath=\"Cleaned_DS_Jobs.csv\"\n",
    "df = spark.read.csv(filepath, inferSchema=\"True\", header=\"True\")\n",
    "df.printSchema()\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a3bddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------+--------+----+-----------------+--------+------+---------+-----------+------+-----+-------+\n",
      "|Job Title|Salary Estimate|Rating|Location|Size|Type of ownership|Industry|Sector|job_state|company_age|python|spark|tableau|\n",
      "+---------+---------------+------+--------+----+-----------------+--------+------+---------+-----------+------+-----+-------+\n",
      "|        0|              0|     0|       0|  27|               27|      71|    71|        0|          0|     0|    0|      0|\n",
      "+---------+---------------+------+--------+----+-----------------+--------+------+---------+-----------+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to check for null values\n",
    "df.select([count(when(isnull(c) | isnan(c),c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c728bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- Salary Estimate: string (nullable = true)\n",
      " |-- Rating: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Type of ownership: string (nullable = true)\n",
      " |-- Industry: string (nullable = true)\n",
      " |-- Sector: string (nullable = true)\n",
      " |-- job_state: string (nullable = true)\n",
      " |-- company_age: integer (nullable = true)\n",
      " |-- python: integer (nullable = true)\n",
      " |-- spark: integer (nullable = true)\n",
      " |-- tableau: integer (nullable = true)\n",
      " |-- minsalary: integer (nullable = true)\n",
      " |-- maxsalary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1 Split the salary estimate column into two separate fields, min_salary and max_salary, \n",
    "# using PySpark to extract the minimum and maximum salary values from the range \n",
    "# provided. \n",
    "df = df.withColumn(\"minsalary\",split(col(\"Salary Estimate\"),\"-\")[0].cast(\"int\"))\n",
    "df = df.withColumn(\"maxsalary\",split(col(\"Salary Estimate\"),\"-\")[1].cast(\"int\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d72aa81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df = df.withColumn(\"average_salary\", (col(\"minsalary\") + col(\"maxsalary\")) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd78632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df = df.withColumn(\"Rating\" , when(((col(\"Rating\") == -1) | (col(\"Rating\") == 0)) ,1).otherwise(col(\"Rating\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9adc376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "for column in df.columns:\n",
    "    df = df.withColumn(column,when(isnull(col(column)) ,-1).otherwise(col(column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66ce4e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|     trim(Job Title)|              avg|\n",
      "+--------------------+-----------------+\n",
      "|Senior Data Scien...|99.33333333333333|\n",
      "|Clinical Data Ana...|            164.5|\n",
      "|Senior Business I...|             90.0|\n",
      "|Data Analyst/Engi...|            115.5|\n",
      "|Staff BI and Data...|            107.0|\n",
      "|Intelligence Data...|            90.75|\n",
      "|Report Writer-Dat...|             92.5|\n",
      "|Hydrogen/Tritium ...|            148.0|\n",
      "|Business Intellig...|           109.25|\n",
      "|        Data Modeler|            154.0|\n",
      "|Scientist / Group...|            197.5|\n",
      "|Senior Research S...|            105.0|\n",
      "|Software Engineer...|            164.5|\n",
      "|   Sr Data Scientist|           126.75|\n",
      "|COMPUTER SCIENTIS...|            271.5|\n",
      "|Data Scientist/Ma...|            125.5|\n",
      "|Data Scientist - ...|            120.5|\n",
      "|  Decision Scientist|             94.5|\n",
      "|Data Scientist - ...|            97.75|\n",
      "|Data Scientist / ...|            128.5|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "ans = df.groupBy(trim(\"Job Title\")).agg(avg(\"average_salary\").alias(\"avg\"))\n",
    "ans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa61395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+------+-----------------+--------------------+--------------------+--------------------+---------+-----------+------+-----+-------+---------+---------+--------------+---------+\n",
      "|           Job Title|Salary Estimate|Rating|         Location|   Type of ownership|            Industry|              Sector|job_state|company_age|python|spark|tableau|minsalary|maxsalary|average_salary|SizeValue|\n",
      "+--------------------+---------------+------+-----------------+--------------------+--------------------+--------------------+---------+-----------+------+-----+-------+---------+---------+--------------+---------+\n",
      "|   Sr Data Scientist|       137-171 |   3.1|     New York, NY|Nonprofit Organiz...|  Insurance Carriers|           Insurance|       NY|         27|     0|    0|      0|      137|      171|         154.0|   Medium|\n",
      "|      Data Scientist|       137-171 |   4.2|    Chantilly, VA|    Company - Public|Research & Develo...|   Business Services|       VA|         52|     0|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   3.8|       Boston, MA|Private Practice ...|          Consulting|   Business Services|       MA|         39|     1|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   3.5|       Newton, MA|    Company - Public|Electrical & Elec...|       Manufacturing|       MA|         20|     1|    0|      0|      137|      171|         154.0|    Small|\n",
      "|      Data Scientist|       137-171 |   2.9|     New York, NY|   Company - Private|Advertising & Mar...|   Business Services|       NY|         22|     1|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   4.2|Santa Barbara, CA|   Company - Private|Computer Hardware...|Information Techn...|       CA|         10|     1|    1|      0|      137|      171|         154.0|    Large|\n",
      "|Data Scientist / ...|       137-171 |   3.9|    Cambridge, MA|    Company - Public|Biotech & Pharmac...|Biotech & Pharmac...|       MA|         24|     1|    0|      0|      137|      171|         154.0|    Small|\n",
      "|      Data Scientist|       137-171 |   3.5|      Bedford, MA|    Company - Public|Consumer Electron...|              Retail|       MA|         30|     1|    0|      0|      137|      171|         154.0|    Small|\n",
      "|Staff Data Scient...|       137-171 |   4.4|    San Diego, CA|    Company - Public|Computer Hardware...|Information Techn...|       CA|         37|     0|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   3.6|      Chicago, IL|   Company - Private|Enterprise Softwa...|Information Techn...|       IL|          6|     1|    0|      0|      137|      171|         154.0|    Small|\n",
      "|      Data Scientist|       137-171 |   4.5|      Herndon, VA|   Company - Private|Enterprise Softwa...|Information Techn...|       VA|          8|     1|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   4.7|  Saint Louis, MO|   Company - Private|         IT Services|Information Techn...|       MO|          4|     1|    1|      0|      137|      171|         154.0|    Large|\n",
      "|Data Scientist - ...|       137-171 |   3.7|     Richland, WA|          Government|              Energy|Oil, Gas, Energy ...|       WA|         55|     0|    0|      0|      137|      171|         154.0|   Medium|\n",
      "|        Data Modeler|       137-171 |   3.1|   Northbrook, IL|   Company - Private|Chemical Manufact...|       Manufacturing|       IL|         47|     1|    0|      1|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   3.4|   Washington, DC|   Company - Private|          Consulting|   Business Services|       DC|         34|     1|    0|      0|      137|      171|         154.0|   Medium|\n",
      "|Experienced Data ...|       137-171 |   4.4|   Washington, DC|   Company - Private|    Federal Agencies|          Government|       DC|         23|     1|    1|      1|      137|      171|         154.0|   Medium|\n",
      "|      Data Scientist|       137-171 |   3.5|      Memphis, TN|   Company - Private|Chemical Manufact...|       Manufacturing|       TN|         75|     1|    0|      0|      137|      171|         154.0|    Large|\n",
      "|     Data Analyst II|       137-171 |   4.2|        Plano, TX|    Company - Public|Enterprise Softwa...|Information Techn...|       TX|         32|     0|    0|      0|      137|      171|         154.0|    Small|\n",
      "|Medical Lab Scien...|       137-171 |   3.5|   West Grove, PA|Nonprofit Organiz...|Health Care Servi...|         Health Care|       PA|          3|     0|    0|      0|      137|      171|         154.0|    Large|\n",
      "|      Data Scientist|       137-171 |   3.2|     New York, NY|   Company - Private|Computer Hardware...|Information Techn...|       NY|          5|     0|    0|      0|      137|      171|         154.0|    Large|\n",
      "+--------------------+---------------+------+-----------------+--------------------+--------------------+--------------------+---------+-----------+------+-----+-------+---------+---------+--------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "import random\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "values  = [\"Small\",\"Medium\",\"Large\"]\n",
    "def assign():\n",
    "    return random.choice(values)\n",
    "\n",
    "my_udf = udf(assign,StringType())\n",
    "df = df.withColumn(\"SizeValue\",my_udf())\n",
    "df = df.drop(\"Size\")\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65b447c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|SizeValue|avg(average_salary)|\n",
      "+---------+-------------------+\n",
      "|   Medium| 122.22535211267606|\n",
      "|    Small| 123.41463414634147|\n",
      "|    Large|  125.5103305785124|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ans = df.groupBy(\"SizeValue\").agg(avg(\"average_salary\"))\n",
    "ans.show()ta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
